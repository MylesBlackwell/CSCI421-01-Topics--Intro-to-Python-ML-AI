{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2fa9d4-20fd-4cf7-a676-444f55c2bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: ta in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from ta) (2.2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mxbla\\documents\\code\\school code\\csci421-01-topics--intro-to-python-ml-ai\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install ta\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1252298-97d9-43ee-9441-783edaaaeb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta  # technical analysis indicators\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "import glob\n",
    "import warnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc19675-0cdc-4ef8-b9e1-d94bbad58815",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfb662f-e62f-488c-ab0a-63bbc630ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\n"
     ]
    }
   ],
   "source": [
    "dfFile = file_paths = glob.glob(\"data/*.csv\")\n",
    "\n",
    "df_list = []\n",
    "for file in file_paths:\n",
    "    temp = pd.read_csv(file)\n",
    "    # If data has separate 'date' and 'time' columns, combine them\n",
    "    if 'date' in temp.columns and 'time' in temp.columns:\n",
    "        # Example format: date = '2020.01.01', time = '17:00'\n",
    "        temp['time'] = pd.to_datetime(\n",
    "            temp['date'].astype(str) + ' ' + temp['time'].astype(str),\n",
    "            format='%Y.%m.%d %H:%M',  # match '2020.01.01 17:00'\n",
    "            errors='coerce'\n",
    "        )\n",
    "        temp.drop(columns=['date'], inplace=True)\n",
    "    else:\n",
    "        # Otherwise parse 'time' directly\n",
    "        temp['time'] = pd.to_datetime(\n",
    "            temp['time'], errors='coerce'\n",
    "        )\n",
    "    # Set index and append\n",
    "    temp.sort_values('time', inplace=True)\n",
    "    temp.set_index('time', inplace=True)\n",
    "    df_list.append(temp)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "print(\"Next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c525f33-31e0-47a1-a0be-3c3b88e0edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "if 'volume' not in df.columns:\n",
    "    df['volume'] = 0\n",
    "\n",
    "# Compute indicators; fill missing values\n",
    "\n",
    "df = ta.add_all_ta_features(\n",
    "    df,\n",
    "    open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\",\n",
    "    fillna=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# STEP 4: Create Future Return and Labels\n",
    "# ------------------------------------------------\n",
    "future_window = 15  # minutes ahead\n",
    "threshold = 0.0010  # 10 pips threshold\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the RandomForest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, labels[:len(X_train)])  # Labels should not be categorical (use original)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort and get the top 15 features\n",
    "important_features = sorted(zip(importances, features.columns), reverse=True)\n",
    "\n",
    "# Print the top 15 features\n",
    "print(\"Top 15 Features:\")\n",
    "for importance, name in important_features[:15]:  # Show top 15\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "'''\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d43bef2-4fe0-4d91-bef9-fac963883df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    }
   ],
   "source": [
    "df['future_return'] = (df['close'].shift(-future_window) - df['close']) / df['close']\n",
    "\n",
    "#determines if it is a buy, sell, or hold\n",
    "def get_label(row):\n",
    "    if row['future_return'] > threshold:\n",
    "        return 0  # Buy\n",
    "    elif row['future_return'] < -threshold:\n",
    "        return 1  # Sell\n",
    "    else:\n",
    "        return 2  # Hold\n",
    "    \n",
    "df['label'] = df.apply(get_label, axis=1)\n",
    "\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2e0ec4-abf7-4d1c-9023-720f64ad2b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features correlated with label:\n",
      "volatility_atr            -0.334353\n",
      "volatility_kcw            -0.332527\n",
      "volatility_dcw            -0.295318\n",
      "volatility_bbw            -0.264185\n",
      "volatility_ui             -0.223554\n",
      "future_return             -0.211185\n",
      "volatility_dcl             0.102775\n",
      "volatility_bbl             0.102716\n",
      "volatility_kcl             0.101858\n",
      "low                        0.101588\n",
      "trend_psar_up              0.101517\n",
      "others_cr                  0.101270\n",
      "close                      0.101270\n",
      "open                       0.101264\n",
      "momentum_kama              0.101258\n",
      "trend_ema_fast             0.101250\n",
      "trend_ema_slow             0.101246\n",
      "trend_sma_slow             0.101244\n",
      "volatility_bbm             0.101244\n",
      "trend_sma_fast             0.101244\n",
      "volatility_kcc             0.101244\n",
      "trend_ichimoku_a           0.101244\n",
      "trend_ichimoku_base        0.101244\n",
      "trend_ichimoku_conv        0.101244\n",
      "trend_visual_ichimoku_b    0.101243\n",
      "volatility_dcm             0.101242\n",
      "trend_visual_ichimoku_a    0.101240\n",
      "trend_ichimoku_b           0.101231\n",
      "high                       0.100943\n",
      "trend_psar_down            0.100942\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Correlation of all features with label\n",
    "correlations = numeric_df.corr()['label'].drop('label').sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Show top features most correlated with label\n",
    "print(\"Top features correlated with label:\")\n",
    "print(correlations.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58950ea-5b93-43c9-8c5f-ad76d14052bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    }
   ],
   "source": [
    "buy_df = df[df['label'] == 0]\n",
    "sell_df = df[df['label'] == 1]\n",
    "hold_df = df[df['label'] == 2]\n",
    "\n",
    "min_size = min(len(buy_df), len(sell_df))\n",
    "\n",
    "hold_downsampled = resample(hold_df, replace=False, n_samples=min_size, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([buy_df, sell_df, hold_downsampled])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e73dc2c-cba3-4198-9681-dc99f7bc64e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(1.0119127192787012), 1: np.float64(0.9769546262834854), 2: np.float64(1.0119578134284017)}\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "#Data prep\n",
    "df_balanced.dropna(inplace=True)\n",
    "\n",
    "selected_features = [\n",
    "    'volatility_bbl',\n",
    "    'volatility_kcl',\n",
    "    'low',\n",
    "    'trend_psar_up',\n",
    "    'others_cr',\n",
    "    'close',\n",
    "    'open',\n",
    "    'momentum_kama',\n",
    "    'volatility_atr',\n",
    "    'volatility_kcw',\n",
    "    'volatility_dcw',\n",
    "    'volatility_bbw',\n",
    "    'volatility_ui',\n",
    "    'volatility_dcl'\n",
    "]\n",
    "\n",
    "\n",
    "features = df_balanced[selected_features]\n",
    "labels = df_balanced['label']\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "#Normalize feature values using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "#converts languale to catogories\n",
    "y = to_categorical(labels, num_classes=3)\n",
    "\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e5f98-39f4-43da-82fa-6eb38e45eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Now, set up GridSearch for RandomForest hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with RandomForestClassifier\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='precision_weighted')\n",
    "\n",
    "# Fit the grid search on your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#train\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 classes: buy, sell, hold\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "'''\n",
    "print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e08100-1216-4b3d-94ea-140c9b12f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions, e.g., classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a195d93-fd7d-4096-84ed-d9bb4f8b8bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m852/852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.44      0.54      0.49      8984\n",
      "        Sell       0.45      0.31      0.36      9307\n",
      "        Hold       0.67      0.74      0.70      8959\n",
      "\n",
      "    accuracy                           0.53     27250\n",
      "   macro avg       0.52      0.53      0.52     27250\n",
      "weighted avg       0.52      0.53      0.52     27250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pred_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "print(classification_report(true_classes, pred_classes, target_names=['Buy', 'Sell', 'Hold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc3020-00d5-493c-af1e-9ce0935cf201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
